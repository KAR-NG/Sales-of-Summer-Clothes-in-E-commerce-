---
title: "Data Analysis plus model development for product success"
author: "Kar Ng"
date: "2021"
output: 
  github_document: 
    toc: true
    toc_depth: 4
always_allow_html: yes

---


***



***


## 1 R Libraries

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(kableExtra)
library(skimr)
library(lubridate)
library(hrbrthemes)
library(hrbrthemes)
library(tidytext)
library(ggExtra)
library(patchwork)
library(tidytext)
library(corrplot)

# Format setting

options(scipen = 999)

```


## 2 Introduction

This project will analyse a public dataset on *Kaggle* website, named "Sales of Summer clothes in E-commerce Wish". As the name suggests, this dataset will include information related to the sales of summer clothes on Wish. There are 43 columns of variables in the dataset including price, units_sold, rating, tags, colour, countries shipped to and etc.

A series of tasks that this project will answer include:

* How about trying to validate the established idea of human sensitiveness to price drops ?

* You may look for top categories of products so that you know what sells best

* Do bad products sell ? How about the relationship between the quality of a product (ratings) and its success ? Does the price factor into this ?

* Do seller's fame factor into top products ?

* Do the number of tags (making a product more discoverable) factor into the success of a product ?

Two popular data analysis techniques will be applied - exploratory data analysis and machine learning. The machine learning technique is to build models and choose the best one to predict *how well a product is going to sell*.


## 3 Data Preparation

The dataset is downloaded from kaggle website, visit this [Link](https://www.kaggle.com/jmmvutu/summer-products-and-sales-in-ecommerce-wish/tasks?taskId=1617) and uploaded to R to complete the analysis. 

### 3.1 Data Importation

```{r}
cloth <- read_csv("summer.csv")
```


### 3.2 Data Description


```{r}

Variable <- names(cloth)

Description <- c("Title for localized for european countries. May be the same as title_orig if the seller did not offer a translation.", 
                 "Original english title of the product.",
                 "Price you would pay to get the product.",
                 "Reference price for similar articles on the market, or in other stores/places. Used by the seller to indicate a regular value or the price before discount.",
                 "Currency of the prices.",
                 "Number of units sold. Lower bound approximation by steps",
                 "Whether the seller paid to boost his product within the platform (highlighting, better placement or whatever)",
                 "Mean product rating.",
                 "Total number of ratings of the product",
                 "Number of 5-star ratings",
                 "Number of 4-star ratings",
                 "Number of 3-star ratings",
                 "Number of 2-star ratings",                 
                 "Number of 1-star ratings",
                 "Number of badges the product or the seller have",
                 "A badge that denotes the product is a local product. Conditions may vary (being produced locally, or something else). Some people may prefer buying local products rather than. 1 means Yes, has the badge",
                 "Badge awarded when many buyers consistently gave good evaluations. 1 means Yes, has the badge",
                 "Badge awarded when this product's order is consistently shipped rapidly",
                 "tags set by the seller",
                 "Product's main color",
                 "One of the available size variation for this product",
                 "Inventory the seller has. Max allowed quantity is 50",
                 "shipping_option_name",
                 "shipping price",
                 "whether the shipping is express or not. 1 for True",
                 "Number of countries this product is shipped to. Sellers may choose to limit where they ship a product to",
                 "Total inventory for all the product's variations (size/color variations for instance)",
                 "Whether there was an urgency banner with an urgency",
                 "A text banner that appear over some products in the search results.",
                 "origin_country",
                 "Merchant's displayed name (show in the UI as the seller's shop name)",
                 "Merchant's canonical name. A name not shown publicly. Used by the website under the hood as a canonical name. Easier to process since all lowercase without white space",
                 "The subtitle text as shown on a seller's info section to the user. (raw, not preprocessed). The website shows this to the user to give an overview of the seller's stats to the user. Mostly consists of `% <positive_feedbacks> (<rating_count> reviews)` written in french",
                 "Number of ratings of this seller",
                 "merchant's rating",
                 "merchant unique id",
                 "Convenience boolean that says whether there is a `merchant_profile_picture` url",
                 "Custom profile picture of the seller (if the seller has one). Empty otherwise",
                 "url to the product page. You may need to login to access it",
                 "Product_picture",
                 "product identifier. You can use this key to remove duplicate entries if you're not interested in studying them.",
                 "the search term used in the search bar of the website to get these search results.",
                 "meta: for info only.")


data.frame(Variable, Description) %>% 
  kbl(caption = "Adapated from the Kaggle Website.") %>% 
  kable_styling(bootstrap_options = c("striped", "bordered"))
  
  

```

### 3.3 Data Exploration

The dataset has 1573 rows of observation and 43 columns of variables. Variables are currently categorised into 2 types, which are character and numeric. 


```{r}
skim_without_charts(cloth)
```

Looking at the "complete_rate", I see that *urgency_text*, *merchant_profile_picture*, and *has_urgency_banner* have too many missing data with a very low complete rate of less than 30%. They will be removed during data cleaning.   

Here provides another way of looking at missing values in the dataset. 

```{r}
colSums(is.na(cloth))

```

Looking at the dataset horizontally with the listing of some values within each variables and their classified type in R. This will helps to see which variables are irrelevant to this project and should be removed. 

```{r}
glimpse(cloth)

```

I identify that following variables can be removed for various reasons. 

* *title*: Redundant. We have already the translated title in the second column.    
* *currency_buyer*: Only one currency "EUR", it doesn't provide analysis insight.    
* *merchant_profile_picture*: Contain too many missing values, complete rate was only 14%. This column is also redundant. relevant column indicating the existence of profile picture already.        
* *has_urgency_banner*, complete rate was only 30%.     
* *urgency_text*: Contain too many missing values, complete rate was only 30%.       
* *merchant_id*: Redundant. I am not interested in individual merchant, it is an overall analysis.       
* *product_url*: I do not need this column for this analysis.    
* *product_picture*: I do not need this column for this analysis.   
* *product_id*: I do not need this column for this analysis.   
* *theme*: Only "summer" in the entire dataset, this column wouldn't contribute much to the analysis of this project.      

```{r}

c <- cloth %>% 
  mutate(theme = as.factor(theme))

levels(c$theme)

```
* *crawl_month*: Only "2020-08-01" in the entire dataset, this column wouldn't contribute much to the analysis of this project.  

```{r}

c <- cloth %>% 
  mutate(crawl_month = ym(crawl_month))

summary(c$crawl_month)

```

## 4 Data Cleaning

Major tasks in this section:

* Remove unrelated variables  
* Manage missing values  
* Convert character and some numerical variables into factor 


### 4.1 Remove variables

This section removes variables that have been previously identified to be redundant or irrelevant to this project.  

* *title*     
* *currency_buyer*  
* *merchant_profile_picture*  
* *has_urgency_banner*     
* *urgency_text*        
* *merchant_id*      
* *product_url*     
* *product_picture*   
* *product_id*    
* *theme*  
* *crawl_month*

```{r}

# Preserving the original data "cloth", and create a new variable "cloth2" 

cloth2 <- cloth %>% 
  dplyr::select(-title, -currency_buyer, -merchant_profile_picture, -has_urgency_banner, 
                -urgency_text, -merchant_id, -product_url, -product_picture, -product_id, 
                -theme, -crawl_month)


```

I will assess the remaining variables again in later stage and would remove them if I found that they don't provide value to this analysis.  


### 4.2 Remove missing values

This section removes 116 rows of data, which is 7.37% of the overall dataset. The dataset drops from 1573 rows of data to 1457. 

```{r}
cloth2 <- na.omit(cloth2)

(count(cloth) - count(cloth2))/count(cloth) * 100


```

There are ways to manage missing values such as imputation using mean, median, or machine learning models. However, I remove the missing values for simplicity of this project. Only 7.37% of data is removed, and I still have 92.63% (1457 rows) of data for this analysis. 

Why missing values need to be managed? It would affect the result of any metrics, for example, the average, as well as affecting the performance of machine learning models. 



### 4.3 Factor conversion

In order for effective analysis, convert character variables into factor is essential. Additionally, some numeric variables will be converted into factor type such as binary vector or vector that uses numbers for grouping purposes. 

Converting data into factor helps (1) the overall R processing speed, (2) initial the role of these numbers in data categorisation, (3) Enable some functions of R that require vectors to be in factor format. 

```{r}

cloth2 <- cloth2 %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(uses_ad_boosts = as.factor(uses_ad_boosts),       # A binary data for yes or not 
         shipping_is_express = as.factor(shipping_is_express),  # A binary data for yes or not 
         merchant_has_profile_picture = as.factor(merchant_has_profile_picture)  # A binary data for yes or not 
         )



```


### 4.4 Typos in the factor variables

I will check typos in the factor variables (character type) that are useful for data categorisation during analysis. An important criteria I will check on is the number of repetitation within these factors. The factor with high repetition of levels will be assessed in this section. 

I have identified them, which are:

* product_color    
* product_variation_size_id  
* origin_country  

**1. Product_color**

A lot of typos need to be cleaned, which are:

* *army green* and *Army green* into *armygreen*
* *Black* into *black*
* *Blue* into *blue*
* *gray* into *grey*
* *light green* into *lightgreen*
* *navy blue* into *navyblue*
* *Pink* into *pink*
* *RED* into *red*
* *Rose red* into *rosered*
* *White* into *white*
* *wine red* into *winered*

```{r}
summary(cloth2$product_color)

```

```{r}
# Rectification

cloth2 <- cloth2 %>% 
  mutate(product_color = as.character(product_color),
         product_color = case_when(product_color == "army green" ~ "armygreen",
                                   product_color == "Army green" ~ "armygreen",
                                   product_color == "Black" ~ "black",
                                   product_color == "Blue" ~ "blue",
                                   product_color == "gray" ~ "grey",
                                   product_color == "light green" ~ "lightgreen",
                                   product_color == "*navy blue" ~ "navyblue",
                                   product_color == "Pink" ~ "pink",
                                   product_color == "RED" ~ "red",
                                   product_color == "Rose red" ~ "rosered",
                                   product_color == "White" ~ "white",
                                   product_color == "wine red" ~ "winered",
                                   TRUE ~ product_color),
         product_color = as.factor(product_color))


```


**2. product_variation_size_id**

The data is too messy in this column. I am doing some buik computation to aid the cleaning a little. Trim leading and trailing white space, remove punctuation, and set all levels to Upper case. 

```{r}
cloth2 <- cloth2 %>% 
  mutate(product_variation_size_id = str_to_upper(product_variation_size_id),
         product_variation_size_id = str_replace_all(product_variation_size_id, "[[:punct:]]", " "),
         product_variation_size_id = trimws(product_variation_size_id),
         product_variation_size_id = as.factor(product_variation_size_id))

summary(cloth2$product_variation_size_id) %>% kbl()
  
```

Grouping some of the identifiable size categories. 

```{r}

cloth2 <- cloth2 %>% 
  mutate(product_variation_size_id = as.character(product_variation_size_id),
         product_variation_size_id = case_when(product_variation_size_id == "2XL" ~ "XXL", 
                                               product_variation_size_id == "3XL" ~ "XXXL", 
                                               product_variation_size_id == "4XL" ~ "XXXXL", 
                                               product_variation_size_id == "5XL" ~ "XXXXXL", 
                                               product_variation_size_id == "SIZE S" ~ "S", 
                                               product_variation_size_id == "SIZE XXS" ~ "XXS", 
                                               product_variation_size_id == "SIZE 4XL" ~ "XXXL", 
                                               product_variation_size_id == "SIZE 5XL" ~ "XXXXXL", 
                                               product_variation_size_id == "SIZE M" ~ "M", 
                                               product_variation_size_id == "SIZE S" ~ "S", 
                                               product_variation_size_id == "SIZE XS" ~ "XS", 
                                               product_variation_size_id == "SIZE XXS" ~ "XXS", 
                                               product_variation_size_id == "SIZE4XL" ~ "XXXXL", 
                                               product_variation_size_id == "SIZEL" ~ "L",
                                               product_variation_size_id == "SIZEL" ~ "L",
                                               TRUE ~ product_variation_size_id),
         product_variation_size_id = as.factor(product_variation_size_id))

```



**3. origin_country**

Nothing to rectify in this column.

```{r}

summary(cloth2$origin_country)

```


### 4.5 Examining the Rating

There are 5 columns for different counts of rating and a "rating_count" representing the total number of rates received. In the aim of analysis of this project, I do not need these columns because I only need the "rating" column which indicates the overall rating.

```{r}
rate <- cloth2 %>% dplyr::select(rating, rating_count, rating_five_count, rating_four_count, rating_three_count,
                                 rating_two_count, rating_one_count)

rate

```

Therefore, I will remove these columns.

```{r}
cloth2 <- cloth2 %>% dplyr::select(-rating_count, -rating_five_count, -rating_four_count, 
                         -rating_three_count, -rating_two_count, -rating_one_count)

```

### 4.6 New Metric: price_drop

The "price" in the dataset is the price that an item will be sold at, whereas "retail_price" is a reference price or regular price and is generally higher than the "price" column. Both will be shown on the product listing page for marketing purposes.

It will be interesting to see how is a product sold based on price dropped. This drop of prices will be calculated here and visualized in the next stage. 


```{r}

cloth2 <- cloth2 %>% 
  mutate(price_drop = retail_price - price) %>% 
  relocate(price_drop, .after = retail_price)

```

Basic statistics of this "price_drop" column are:

```{r}

summary(cloth2$price_drop)

```

### 4.6 New Metric: discount_per

Based on the newly created "price_drop", a discount percentage "discount_per" is synthesised to help to study the effect of price dropped on sales. 

```{r}

cloth2 <- cloth2 %>% 
  mutate(discount_per = round(price_drop/retail_price*100), 2) %>% 
  relocate(discount_per, .after = price_drop)

```

Basic statistics of this "discount_per" column are:

```{r}

summary(cloth2$discount_per)

```

Why don't we use price_drop instead? Because produces are sold at different prices, the sample sizes of expensive products are different than the products at cheaper prices. Creating a discount percentage columne (discount_per) will aid the scale down the value to make our observation easier (Hopefully).
 

### 4.7 New Metric: price_class

It can be useful to create classes for different prices. Based on the dataset, the price ranges between 0 to 50. 


```{r}
summary(cloth2$price)

```
The result of the classes.

```{r}
cloth2 <- cloth2 %>% 
  mutate(price_class = case_when(price < 10 ~ "EUR<10",
                                 price > 10 & price < 20 ~ "EUR10-20",
                                 price > 20 & price < 30 ~ "EUR20-30",
                                 price > 30 & price < 40 ~ "EUR30-40",
                                 TRUE ~ "EUR40-50"),
         price_class = as.factor(price_class)) %>% 
  relocate(price_class, .after = price)

levels(cloth2$price_class)

```





## 5 Visualisation

This section will analyse the 5 main tasks listed in the introduction.

### 5.1 Validated! Human sensitive to price drops

This section answers the first task of this project - **How about trying to validate the established idea of human sensitiveness to price drops ?**

It will be in relevant to the sales of a product in relation to the magnitude of it's price drops. I will use discount in percentage (price drop/retail price * 100) to represent price drops for each of these 1457 items in the dataset.

Following is the first graph, it appears that there is no obvious relation between discounts and unit sold. 


```{r, fig.width=10, fig.height=6, warning=FALSE}

p1 <- ggplot(cloth2, aes(x = discount_per, y = units_sold)) +
  geom_jitter(size = 4, alpha = 0.2, colour = "green") +
  labs(x = "Discount (%)",
       y = "Unit Sold (Quantity)",
       title = "Unit Sold versus Discounts ($)") +
  theme_modern_rc() +
  theme(plot.title = element_text(size = 16, face = "bold")) +
  scale_y_continuous(labels = function(x)paste0((x/1000), "k"))


p1

```

However, following bar chart shows that in term of the total number of products sold from different discount classes, it is definitely that a discount rate between 75% to near 100% will outcompete other discount classes.

```{r, fig.width=9, warning=FALSE}

df1 <- cloth2 %>% 
  select(discount_per, units_sold) %>% 
  mutate(class = case_when(discount_per < 0 ~ "0%",
                           discount_per > 0 & discount_per < 25 ~ "0-25%",
                           discount_per > 25 & discount_per < 50 ~ "25-50%",
                           discount_per > 50 & discount_per < 75 ~ "50-75%",
                           TRUE ~ "75-100%"),
         class = factor(class, levels = c("0%", "0-25%", "25-50%", "50-75%", "75-100%"))) %>% 
  group_by(class) %>% 
  summarise(total = sum(units_sold)) 



p2 <- ggplot(df1, aes(x = class, y = total, fill = class)) +
  geom_bar(stat = "identity", colour = "black") +
  geom_label(aes(label = prettyNum(total, big.mark = ",")), vjust = -1, fill = "grey") +
  labs(x = "Discounts",
       y = "Total Sold (Count)",
       title = "More Items Sold at Higher Discount Rate (%)") +
  scale_y_continuous(labels = function(x)paste0((x/1000000), " Mil"),
                     lim = c(0, 3000000)) +
  theme_modern_rc() +
  theme(legend.position = "none",
        plot.title = element_text(face = "bold"),
        axis.title.y = element_text(margin = margin(0, 10, 0, 0)),
        axis.title.x = element_text(margin = margin(10, 0, 0, 0)))

p2

```

Please be aware. This result shows a tend but is not a well-designed proper experiment. It is a trend based on collected observation. However, it do show a trend that the higher the discount rate, the more the total number of items sold. It may help to conclude that human is sensitive towards price. 
 
To explain why discount rate at "0%" has the highest items sold, it is because that human sensitivity to price drops is a complex mechanism. For examples, there are much more items that are sold at 0% have their prices already much cheaper than the discounted items, regardless of price-drop magnitude. Though these items are having far cheap prices but also having a value that is enough to build trust from consumer and made their purchases succeed. 



### 5.2 Typical top product categories 

Second analysis task of this project: **Look for top categories of products so that you know what sells best.**

Identify that following variables can help to answer this task.

* product_color  
* product_variation_size_id  

Setting up data frame with relevant variables. 

```{r}
df2 <- cloth2 %>% dplyr::select(units_sold, product_color, product_variation_size_id)

```
**1. product_color** 

There are 87 colour categories and a few colours dominating the majority of the sales. It is quite *pareto*. The top 5 colours are black, white, grey, purple, and blue. 


```{r, fig.width=10, fig.height=12, warning=FALSE}

# df

color_df <- df2 %>% 
  group_by(product_color) %>% 
  summarise(total = sum(units_sold))

# plot

p3 <- ggplot(color_df, aes(y = fct_reorder(product_color, total), x = total, group = 1)) +
  geom_point(size = 3) +
  geom_line(size = 1) +
  theme_modern_rc() +
  labs(x = "Total Sold per Item Category",
       y = "Colour Category",
       title = "Top 5 Best-Selling Colours are Black, White, Grey, Purple, and Blue") +
  theme(plot.title = element_text(size = 17)) +
  scale_x_continuous(labels = function(x)(prettyNum(x, big.mark = ",")))


p3 

```

**2. product_variation_size_id** 

Another *pareto* trend. There are 63 different level of size "classes" in the dataset. The top 5 best-selling sizes are S, M, XS, L and XXS.

```{r, fig.width=10, fig.height=12, warning=FALSE}

# df

size_df <- df2 %>% 
  group_by(product_variation_size_id) %>% 
  summarise(total = sum(units_sold))

# plot

p4 <- ggplot(size_df, aes(y = fct_reorder(product_variation_size_id, total), x = total, group = 1)) +
  geom_point(size = 3, color = "yellow") +
  geom_line(size = 1, color = "yellow") +
  theme_modern_rc() +
  labs(x = "Total Sold per Item Category",
       y = "Size Category",
       title = "Top 5 Best-Selling Sizes are S, M, XS, L and XXS") +
  theme(plot.title = element_text(size = 17)) +
  scale_x_continuous(labels = function(x)(prettyNum(x, big.mark = ",")))

p4

```



### 5.3 The Effect of Rating on Sales

The third analysis task: **Do bad products sell ? How about the relationship between the quality of a product (ratings) and its success ? Does the price factor into this ?**

Yes, the better the rating, the better the sales of the product. From following plot, I can see that as long as the product has a rating of above 3, it will sell. 

The price does not have obvious relationship with the rating and sales.

```{r, fig.width=9, fig.height=6, warning=FALSE}

p5 <- ggplot(cloth2, aes(x = rating, y = units_sold, colour = price_class)) +
  geom_point(size = 3, alpha = 0.4) +
  theme_modern_rc() +
  labs(x = "Product Rating (1 - 5)",
       y = "Units Sold (Count)",
       title = "Best Performing Rating Falls Between 3 - 5") +
  theme(plot.title = element_text(vjust = 2)) +
  facet_wrap(~price_class) +
  scale_y_continuous(labels = function(x)(prettyNum(x, big.mark = ",")))


p5

```


### 5.4 Logarithmically graphing the Fame

The fourth analysis task of this project asked: **Do seller's fame factor into top products?**

There are two options here, whether I should use "merchant_rating_count" or "merchant_rating" for this analysis. The "merchant_rating_count" indicates total number of rating, which would indirectly tell how popular a seller is. On the other hand, "merchant_rating" will only give the overall rating of a seller, and it won't tell how many buyers are voting for the seller.

Therefore, I will use "merchant_rating_count" to be a better indication of "fame factor" specified by the task.

```{r, warning=FALSE, fig.width=12, fig.height=8, message=FALSE}

library(patchwork)


df5 <- cloth2 %>% dplyr::select(units_sold, product_color, product_variation_size_id, 
                                  merchant_rating_count, merchant_rating_count, merchant_rating)


p1 <- ggplot(df5, aes(x = log(merchant_rating_count), y = units_sold)) +
  geom_point(colour = "orange", shape = 21, size = 4) +
  geom_smooth(colour = "white") +
  theme_modern_rc() +
  labs(x = "log(Merchant Rating Count)",
       y = "Unit Sold (Count)",
       title = "logarithmic") 
  

df5 <- cloth2 %>% dplyr::select(units_sold, product_color, product_variation_size_id, 
                                  merchant_rating_count, merchant_rating_count, merchant_rating)


p2 <- ggplot(df5, aes(x = merchant_rating_count, y = units_sold)) +
  geom_point(colour = "pink", shape = 21, size = 4) +
  geom_smooth(colour = "white") +
  theme_modern_rc() +
  labs(x = "Merchant Rating Count",
       y = "Unit Sold (Count)",
       title = "Arithmetic") +
  scale_x_continuous(labels = function(x)(prettyNum(x, big.mark = ",")))

mypatch <- p2 + p1 & theme_modern_rc() 

mypatch + 
  plot_annotation(title = "Gentle Relationship between Fame and Sales") +
  theme(text = element_text(size = 40))
  

```

*Insights*

* The fame of a merchant is important but not critical.  
* Sales will increase with the popularity of a merchant.  
* However, the relationship is not absolute proved by the evidence of arithmetic graph. 


### 5.5 Tags (Text) Analysis


The fifth question: *Do the number of tags (making a product more discoverable) factor into the success of a product ?*


```{r, fig.width=8, fig.height=6, warning=FALSE}

# df 

df5 <- cloth2 %>% 
  dplyr::select(merchant_name, price_class, price, units_sold, tags) %>% 
  mutate(tags = as.character(tags))

seller_tags <- df5 %>% 
  unnest_tokens(input = tags, output = word) %>%        # Tokenise tags 
  group_by(merchant_name) %>% 
  summarise(tags_count = n()) %>% 
  arrange(desc(tags_count))

# join tables

df5.2 <- df5 %>% 
  left_join(seller_tags, by = "merchant_name")

# plot

ggplot(df5.2, aes(x = tags_count, y = units_sold)) +
  geom_hex(bins = 40, colour = "grey") +
  theme_modern_rc() +
  theme(legend.position = "right",
        plot.title = element_text(face = "bold", size = 14, vjust = 2)) +
  labs(title = "Tags are Required But No Direct Impacts On Product Success",
       x = "Number of Tags",
       y = "Units Sold") +
  scale_y_continuous(labels = function(x)(prettyNum(x, big.mark = ","))) 



```


## 6 Staitistcal Analysis

This section will start to evaluate the statistical relationship between *how well a product is sold* with all other relevant variables. The responding variable will be "units_sold".


### 6.1 Feature Selection

**Primary Addition**

The number of tags in relation to the number of each product sold will be very interesting to include. This value can be attracted from the "tags" column that has a massive amount of text describing relevant tags. This extraction has been done in section 5.5. Here, I will just add the extracted column into the current dataset. 

```{r}
cloth2 <- cloth2 %>% 
  left_join(seller_tags, by = "merchant_name")


```

**Primary Removing**

This section will remove variables that is irrelevant to this analysis based on my domain knowledge. I will based on the characteristics of a feature, for examples (1) if there are too many missing values in that column (I have done it during data cleaning), (2) The data in the column do not help in categorising the data such as having non-repeated unique values in the entire column, (3) The column is basically irrelevant to the predictive objective.  

Variables I am removing include:

* title_orig  
* tags  
* merchant_title   
* merchant_name  
* merchant_info_subtitle  
* the accidentally induced column - "2"     

```{r}

cloth3 <- cloth2 %>% dplyr::select(-title_orig, -tags, -merchant_title, -merchant_name, -merchant_info_subtitle, -'2')

```

### 6.2 EDA

#### 6.2.1 Histogram

Following histogram looks for the trends of all numerical variables.

```{r, fig.width=12, fig.height=12, warning=FALSE}

# df

df.his <- cloth3 %>% 
  gather(key = "key", value = "value") %>% 
  mutate(value = as.numeric(value))

# plot

ggplot(df.his, aes(x = value, fill = key)) + 
  geom_histogram(colour = "black") +
  facet_wrap(~key, scale = "free") +
  theme_modern_rc() +
  theme(legend.position = "none",
        strip.text = element_text(colour = "white", size = 10)) 
  

```

*Insights*

* Identify that *badge_fast_shipping*, *badge_local_product*, *badge_product_quality*, *merchant_has_profile_picture*, *uses_ad_boosts*, and *shipping_is_express* are binary variable and should be converted to factor. 

```{r}
cloth3 <- cloth3 %>% 
  mutate(badge_fast_shipping = as.factor(badge_fast_shipping),
         badge_local_product = as.factor(badge_local_product),
         badge_product_quality = as.factor(badge_product_quality),
         merchant_has_profile_picture = as.factor(merchant_has_profile_picture),
         uses_ad_boosts = as.factor(uses_ad_boosts),
         shipping_is_express = as.factor(shipping_is_express))

```

* *inventory_total* is a numerical variable with only single value of 50, information gaining from this variable in relation to the number of product soil will be limited. Therefore, this variable will be removed.

```{r}
cloth3 <- cloth3 %>% dplyr::select(-inventory_total)

```


* Most variables have skewed distribution, variables that has high potential predictive power (Gaussian distributed) are country_shiped to, merchant rating, price, rating, and perhaps tags_count.

* A non-parametric machine learning algorithm should applied for this dataset.


Following histogram looks for the trends of all categorical variables.


```{r, warning=FALSE, fig.height=20, fig.width=12}

his_cat <- cloth3 %>% 
  dplyr::select(origin_country, price_class, product_color, shipping_option_name) 

his_cat <- his_cat %>% 
  gather(key = "key", value = "value") %>% 
  group_by(key, value) 
  

ggplot(his_cat, aes(y = reorder(value, table(value)[value]), colour = key)) +
  geom_bar(fill = "black") +
  facet_wrap(~key, scale = "free", ncol = 1, nrow = 4) +
  theme_modern_rc() +
  theme(legend.position = "none",
        strip.text = element_text(colour = "white"))


```

From above graph, we are able to see which categorical level are the dominant ones. Product color might be harder to see and so I provide an alternative zoomed version before with count higher than 50. 

```{r, message=FALSE, fig.width=8, fig.height=8}

his_cat_color <- his_cat %>% 
  filter(key == "product_color") %>% 
  group_by(value) %>% 
  summarise(count = n()) %>% 
  filter(count > 20)
  
ggplot(his_cat_color, aes(y = fct_reorder(value, count), x = count, colour = value)) +
  geom_bar(fill = "black", stat = "identity") +
  theme_modern_rc() +
  theme(legend.position = "none") +
  labs(x = "Count",
       y = "Product Colour",
       title = "Zoomed in to Dominant Product Colour (Count > 50)")

```


#### 6.2.2 Boxplot

Applying boxplot to visualise the existence of outliers and how are data distributed in the form of box plot in each feature.  

```{r,warning=FALSE, fig.width=12, fig.height=9}

# df

df.box <- cloth3 %>% 
  select(is.numeric) %>% 
  gather(key = "key", value = "value") %>% 
  mutate(value = as.numeric(value))

# plot

ggplot(df.box, aes(x = value, fill = key)) +
  geom_boxplot(colour = "white") +
  facet_wrap(~key, scale = "free", ncol = 5, nrow = 3) +
  theme_modern_rc() +
  theme(legend.position = "none",
        strip.text = element_text(size = 12, colour = "white"))

```

There are many outliers in each features. It may affect the assumption of regression models and a non-parametric machine learning model that immune to outlier should be applied. 


#### 6.3.3 Relationship Curve

* Relationship between 

```{r, fig.width=10, fig.height=10}

df_rela <- cloth3 %>% 
  select(is.numeric) %>% 
  gather(key = "key", value = "value", -units_sold) 

 
ggplot(df_rela, aes(x = value, y = units_sold, colour = key)) +
  geom_point(alpha = 0.5) +
  facet_wrap(~key, scales = "free") +
  theme_bw() +
  theme(legend.position = "none",
        plot.title = element_text(face = "bold", size = 14, hjust = 0.5, vjust = 2),
        strip.text = element_text(size = 10)) +
  geom_smooth(se = F) +
  labs(x = "Variables",
       y = "Units Sold",
       title = "Relationship between Numeric Predictors with Units Sold")

```

The relationship between each predictors with the "units sold" (It can be understood as how well a product is sold) is complex. It is a rare situation where graphical transformation of data doesn't help much. I will apply inferential model later to help interpretation. 


#### 6.3.3 Correlogram 

This section is to check multicollinearity between numerical predictors. As a rule of thumb, the pair of predictors with correlation above 0.8 should have one removed among the both to avoid multicollinearity problem. If it is not done, the standard errors of coefficients estimates during regression analysis will be inflated, and may affect the accuracy of respective P-values. I will also apply VIF to support the decisions made in this correlogram. 

**Insights:**

* "Shipping_option_price" and "price" has correlation higher than 0.80  
* "retail_price" and "retail_price" has correlation higher than 0.80  


```{r, fig.width=10, fig.height=10}

df_cor <- cloth3 %>% 
  select(is.numeric)

corrplot(cor(df_cor), method = "number", type = "upper")

```

This feature selection will be handled in next section.


### 6.3 Inferential Model

In this real dataset, pareto principle (80:20) is applied heavily, where in the categorical variables, most of the data are concentrated in certain levels and in a result, the remaining levels have insufficient for efficient modeling.

This is happening to the "shipping_option_name", "product_variation_size_id", and "colour". Therefore I will try to group the level with less data into "other" category to help analysis. 


**1. shipping_option_name**

Examining the distribution of sample sizes:

```{r}

cloth3 %>% 
  select(shipping_option_name) %>% 
  group_by(shipping_option_name) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count)) %>% 
  ungroup() %>% 
  mutate(total = sum(count),
         proportion = count/total) %>% 
  kable(align = "c")

```

Keep only Livraison standard and group all other shipping option in "other_shipping". I will also remove the original shipping_option_name column.

```{r}
# The codes

cloth3 <- cloth3 %>% 
  mutate(shipping_option_name = as.character(shipping_option_name),
         shipping_name = case_when(shipping_option_name != "Livraison standard" ~ "Other_shipping",
                                           TRUE ~ shipping_option_name),
         shipping_name = as.factor(shipping_name)) %>% 
  dplyr::select(-shipping_option_name)

# The result

cloth3 %>% 
  select(shipping_name) %>% 
  group_by(shipping_name) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count)) %>% 
  ungroup() %>% 
  mutate(total = sum(count),
         proportion = count/total) %>% 
  kable(align = "c")
```

**2. product_variation_size_id**

Examine the sample size of each level:  

```{r}

cloth3 %>% 
  select(product_variation_size_id ) %>% 
  group_by(product_variation_size_id ) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count)) %>% 
  ungroup() %>% 
  mutate(total = sum(count),
         proportion_percentage = count/total * 100) %>% 
  kable(align = "c")

```


* I will keep only S, XS, M, XXS, L, XXL, and XL, they contribute roughly 90% of to the dataset, and grouping the rest of the levels into "other size"


```{r}

# The codes

cloth3 <- cloth3 %>% 
  mutate(product_variation_size_id = as.character(product_variation_size_id),
         product_sizes = case_when(product_variation_size_id == "S" ~ "S",
                                   product_variation_size_id == "XS" ~ "XS",
                                   product_variation_size_id == "M" ~ "M",
                                   product_variation_size_id == "XXS" ~ "XXS",
                                   product_variation_size_id == "L" ~ "L",
                                   product_variation_size_id == "XXL" ~ "XXL",
                                   product_variation_size_id == "X" ~ "X",
                                           TRUE ~ "Other_sizes"),
         product_sizes = as.factor(product_sizes)) %>% 
  dplyr::select(-product_variation_size_id)

# Checking

cloth3 %>% 
  select(product_sizes) %>% 
  group_by(product_sizes) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count)) %>% 
  ungroup() %>% 
  mutate(total = sum(count),
         proportion_percentage = count/total * 100) %>% 
  kable(align = "c")

```

**3. product_color**

Lastly, I apply the same technique to "product_color". Examine the sample sizes of its levels:

```{r}

cloth3 %>% 
  select(product_color) %>% 
  group_by(product_color) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count)) %>% 
  ungroup() %>% 
  mutate(total = sum(count),
         proportion_percentage = count/total * 100) %>% 
  kable(align = "c")


```



```{r}

```






















## 7 Predictive Aanalysis

The machine learning technique is to build models and choose the best one to predict *how well a product is going to sell*.


```{r}
model_mlr <- cloth3

```









## Legality



## Reference


https://www.kaggle.com/jmmvutu/summer-products-and-sales-in-ecommerce-wish


